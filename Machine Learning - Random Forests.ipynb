{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMS Capstone - Machine Learning - Random Forests\n",
    "## By: AJ Goldstein (https://github.com/ajva1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Modeling Task: </span>\n",
    "### Understand the relationship between psychological inflexibility (i.e. AAQ) and mental health outcomes (i.e. depression, anxiety, well-being) while controlling for key demographic info (i.e. race, gender, field of study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Why Random Forests?</span>\n",
    "- WHY 1: <b>high interpretability & stable feature importances</b>\n",
    "- WHY 2: <b>reduces variance & prevents overfitting</b>\n",
    "- WHY 3: <b>inherently models feature interactions</b>\n",
    "\n",
    "### <span style=\"color:red\">Analysis Steps:</span>\n",
    "- 1) Prepare data for classification\n",
    "- 2) Train a Random Forest Classifier\n",
    "- 3) Optimize Classifier Models\n",
    "- 4) Train a Random Forest Regressor\n",
    "- 5) Optimize Regressor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #0: Carry forward data from previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleaned dataset\n",
    "%store -r HMS\n",
    "\n",
    "# separated modules\n",
    "%store -r HMS_ids\n",
    "%store -r HMS_demo\n",
    "%store -r HMS_mhstatus\n",
    "%store -r HMS_mhhelp\n",
    "%store -r HMS_aaq\n",
    "\n",
    "# tidy variable groups\n",
    "%store -r tidy_race\n",
    "%store -r tidy_religion\n",
    "%store -r tidy_degreeType\n",
    "%store -r tidy_fieldOfStudy\n",
    "%store -r tidy_activity\n",
    "%store -r tidy_age\n",
    "%store -r tidy_gender\n",
    "%store -r tidy_relig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #1: Prepare data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) convert survey demographics & AAQ into features matrix (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns without text \n",
    "cols = [col for col in HMS_demo.columns if ('text' not in col)]\n",
    "X = HMS_demo[cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert them to categorical variables\n",
    "for col in cols:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAQ</th>\n",
       "      <th>age</th>\n",
       "      <th>sex_birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>sexual</th>\n",
       "      <th>relship</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_ainaan</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_his_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>disab_1_1</th>\n",
       "      <th>disab_1_2</th>\n",
       "      <th>disab_1_3</th>\n",
       "      <th>disab_1_4</th>\n",
       "      <th>disab_1_5</th>\n",
       "      <th>disab_1_6</th>\n",
       "      <th>disab_1_7</th>\n",
       "      <th>disab_1_8</th>\n",
       "      <th>disab_1_9</th>\n",
       "      <th>disab_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAQ   age sex_birth gender sexual relship race_black race_ainaan  \\\n",
       "0  NaN  20.0       1.0    2.0    1.0     1.0        0.0         0.0   \n",
       "1  NaN  21.0       1.0    2.0    1.0     1.0        0.0         0.0   \n",
       "3  NaN  22.0       2.0    1.0    1.0     1.0        0.0         0.0   \n",
       "4  NaN  19.0       2.0    1.0    1.0     6.0        0.0         0.0   \n",
       "5  NaN  21.0       2.0    1.0    1.0     1.0        0.0         0.0   \n",
       "\n",
       "  race_asian race_his_temp   ...   disab_1_1 disab_1_2 disab_1_3 disab_1_4  \\\n",
       "0        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "1        0.0           0.0   ...         0.0       0.0       1.0       0.0   \n",
       "3        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "4        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "5        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "\n",
       "  disab_1_5 disab_1_6 disab_1_7 disab_1_8 disab_1_9 disab_3  \n",
       "0       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "1       0.0       0.0       0.0       0.0       0.0     3.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "4       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "5       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add in AAQ_total score\n",
    "X.insert(loc=0, column = 'AAQ', value = HMS_aaq['AAQ_total'])\n",
    "feat_cols = X.columns\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) remove unapplicable and missing values (NaN's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select three main outcomes\n",
    "Y_flourish = HMS_mhstatus['flourish']\n",
    "Y_depression = HMS_mhstatus['deprawsc']\n",
    "Y_anxiety = HMS_mhstatus['anx_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all variables (X's and Y's) into one dataframe\n",
    "all_variables = pd.concat([X, Y_flourish, Y_depression, Y_anxiety], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape before removing NaNs:', (45756, 103))\n",
      "('shape after removing NaNs:', (22781, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with any NaN\n",
    "print('shape before removing NaNs:', all_variables.shape)\n",
    "all_variables = all_variables.dropna(axis=0, how='any')\n",
    "print('shape after removing NaNs:', all_variables.shape) # NOTE: 25,000+ dropped rows were due to AAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> IMPORTANT NOTE: 25,000+ dropped rows were due to AAQ (half of respondents did not have an AAQ score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape BEFORE removing middle 1/3 of scores:', (22781, 103))\n",
      "('shape AFTER removing middle 1/3 of scores:', (8972, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove middle 1/3 of scores in the \"mild\" range\n",
    "print('shape BEFORE removing middle 1/3 of scores:', all_variables.shape)\n",
    "all_variables = all_variables.loc[~all_variables['flourish'].between(42, 47, inclusive=True)]\n",
    "all_variables = all_variables.loc[~all_variables['deprawsc'].between(5, 9, inclusive=True)]\n",
    "all_variables = all_variables.loc[~all_variables['anx_score'].between(5, 9, inclusive=True)]\n",
    "print('shape AFTER removing middle 1/3 of scores:', all_variables.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> IMPORTANT NOTE: 13,000 rows were dropped from the \"mild\" range of these scores</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big dataframe back up\n",
    "X = all_variables.drop(labels=['flourish', 'deprawsc', 'anx_score'], axis=1)\n",
    "Y_flourish_cleaned = all_variables['flourish']\n",
    "Y_depression_cleaned = all_variables['deprawsc']\n",
    "Y_anxiety_cleaned = all_variables['anx_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) categorize mental health outcomes into classified labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_outcome(value, outcome):\n",
    "    \n",
    "    # flourishing scale\n",
    "    if outcome == 'flourish':\n",
    "        if pd.isnull(value):\n",
    "            return value\n",
    "        elif value < 48:\n",
    "            return 0\n",
    "        elif value >= 48:\n",
    "            return 1\n",
    "        \n",
    "    # depression or anxiety\n",
    "    else:\n",
    "        if pd.isnull(value):\n",
    "            return value\n",
    "        elif value < 10:\n",
    "            return 0\n",
    "        elif value >= 10:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical labels\n",
    "Y_flourish_cats = pd.Series([categorize_outcome(score, 'flourish') for score in Y_flourish_cleaned], name='flourish')\n",
    "Y_depression_cats = pd.Series([categorize_outcome(score, 'depression') for score in Y_depression_cleaned], name = 'depression')\n",
    "Y_anxiety_cats = pd.Series([categorize_outcome(score, 'anxiety') for score in Y_anxiety_cleaned], name = 'anxiety')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">NOTE: using \"moderate\" score of 10 as cutoff for depression/anxiety... 48 as the threshold for positive mental health</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #2: Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0)\n",
    "y_flourish_train, y_flourish_test = train_test_split(Y_flourish_cats, test_size=0.3, random_state=0)\n",
    "y_depression_train, y_depression_test = train_test_split(Y_depression_cats, test_size=0.3, random_state=0)\n",
    "y_anxiety_train, y_anxiety_test = train_test_split(Y_anxiety_cats, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) create and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random forest classifiers\n",
    "dep_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "anx_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "flo_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on all three outcomes\n",
    "dep_clf.fit(X_train, y_depression_train)\n",
    "anx_clf.fit(X_train, y_anxiety_train)\n",
    "flo_clf.fit(X_train, y_flourish_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.366570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.269347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.106480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.093753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.044024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.031884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.017441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>religios</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relig_aff_ch</td>\n",
       "      <td>0.006497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  importance\n",
       "0           AAQ    0.366570\n",
       "1      aca_impa    0.269347\n",
       "2       persist    0.106480\n",
       "3        fincur    0.093753\n",
       "4        sexual    0.044024\n",
       "5       finpast    0.031884\n",
       "6        gpa_sr    0.017441\n",
       "7      religios    0.010687\n",
       "8        gender    0.009129\n",
       "9  relig_aff_ch    0.006497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.376809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.268195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.097090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.091996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.038762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.032272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.015092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_birth</td>\n",
       "      <td>0.013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>religios</td>\n",
       "      <td>0.007450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  importance\n",
       "0        AAQ    0.376809\n",
       "1   aca_impa    0.268195\n",
       "2     fincur    0.097090\n",
       "3    persist    0.091996\n",
       "4     sexual    0.038762\n",
       "5    finpast    0.032272\n",
       "6     gpa_sr    0.015092\n",
       "7     gender    0.014746\n",
       "8  sex_birth    0.013158\n",
       "9   religios    0.007450"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.341590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.230849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.163179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.063896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.050405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>religios</td>\n",
       "      <td>0.026227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.025757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relig_aff_ch</td>\n",
       "      <td>0.011963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relig_aff_at</td>\n",
       "      <td>0.006451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  importance\n",
       "0           AAQ    0.341590\n",
       "1      aca_impa    0.230849\n",
       "2       persist    0.163179\n",
       "3        fincur    0.063896\n",
       "4        sexual    0.050405\n",
       "5      religios    0.026227\n",
       "6       finpast    0.025757\n",
       "7        gpa_sr    0.020467\n",
       "8  relig_aff_ch    0.011963\n",
       "9  relig_aff_at    0.006451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "for clf in [dep_clf, anx_clf, flo_clf]:\n",
    "    features = pd.DataFrame(sorted(zip(feat_cols, clf.feature_importances_),\n",
    "                            key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "    display(features.head(10))\n",
    "    #if clf == dep_clf:\n",
    "    #    display(features.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">AAQ consistently comes out on top as by far the most important feature</span>\n",
    "- #### <span style=\"color:red\">(10x more important than any variable outside the top 5 in predicting mental health outcomes)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) test the accuracy of our full-feature classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression Model Accuracy:', 0.90973254086181277)\n",
      "('Anxiety Model Accuracy:', 0.89635958395245174)\n",
      "('Flourishing Model Accuracy:', 0.84658246656760772)\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred_dep = dep_clf.predict(X_test)\n",
    "y_pred_anx = anx_clf.predict(X_test)\n",
    "y_pred_flo = flo_clf.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Of Our Full Feature Model\n",
    "print('Depression Model Accuracy:', accuracy_score(y_depression_test, y_pred_dep))\n",
    "print('Anxiety Model Accuracy:', accuracy_score(y_anxiety_test, y_pred_anx))\n",
    "print('Flourishing Model Accuracy:', accuracy_score(y_flourish_test, y_pred_flo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:blue\">*** Note to self: add cross-validation here to check for overfitting!*** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) compare performance to baseline measure (dummyClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression BASELINE Accuracy:', 0.54866270430906394)\n",
      "('Anxiety BASELINE Accuracy:', 0.57206537890044573)\n",
      "('Flourishing BASELINE Accuracy:', 0.56723625557206536)\n"
     ]
    }
   ],
   "source": [
    "# Question: \"what if we just guessed the *most common class* everytime?\"\n",
    "y_mode_pred_dep = DummyClassifier(strategy='most_frequent').fit(X_train, y_depression_train).predict(X_test)\n",
    "y_mode_pred_anx = DummyClassifier(strategy='most_frequent').fit(X_train, y_anxiety_train).predict(X_test)\n",
    "y_mode_pred_flo = DummyClassifier(strategy='most_frequent').fit(X_train, y_flourish_train).predict(X_test)\n",
    "\n",
    "# use arrays of mode values to make baseline predictions\n",
    "print('Depression BASELINE Accuracy:', accuracy_score(y_depression_test, y_mode_pred_dep))\n",
    "print('Anxiety BASELINE Accuracy:', accuracy_score(y_anxiety_test, y_mode_pred_anx))\n",
    "print('Flourishing BASELINE Accuracy:', accuracy_score(y_flourish_test, y_mode_pred_flo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> The predictive models created above are 35-40% more accurate than their baseline measures: </span>\n",
    "- #### <span style=\"color:red\">Depression Classifer: ~92% accuracy</span> in predicting whether or not a student is clinically depressed\n",
    "- #### <span style=\"color:red\">Anxiety Classifer: ~90% accuracy </span>in predicting whether or not a student has general anxiety disorder\n",
    "- #### <span style=\"color:red\">Flourishing Classifer: ~85% accuracy </span>in predicting whether or not someone has positive mental health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #3: Optimize Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) optimize hyperparameters using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 12, 'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "rfc = RandomForestClassifier(n_jobs=-1, oob_score = True) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\"criterion\" : ['gini', 'entropy'],\n",
    "              \"n_estimators\" : [500, 1000],\n",
    "              \"max_depth\" : [3, 5, 10, 15],\n",
    "              \"max_features\" : [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\" : [10, 30, 50, 100]}\n",
    " \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_train, y_depression_train)\n",
    "print CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"n_estimators\" : [10, 100, 500, 1000, 10000, 100000],\n",
    "           \"max_features\" : [1, 2, 4, 8, 16, 32],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "            \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) identify and select the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAQ\n",
      "sexual\n",
      "fincur\n",
      "finpast\n",
      "aca_impa\n",
      "persist\n"
     ]
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0\n",
    "sfm = SelectFromModel(clf, threshold=0.03)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_depression_train)\n",
    "\n",
    "# Print the names of the most important features\n",
    "feat_cols_important = []\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    feat_cols_important.append(feat_cols[feature_list_index])\n",
    "    print(feat_cols[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) create a dataset with only the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) train new classifiers using only the most important features ( + optimal hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 10, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_depression_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.505255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.265576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.077233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.072019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.046874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.033042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  importance\n",
       "0       AAQ    0.505255\n",
       "1  aca_impa    0.265576\n",
       "2    fincur    0.077233\n",
       "3   persist    0.072019\n",
       "4   finpast    0.046874\n",
       "5    sexual    0.033042"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "features = pd.DataFrame(sorted(zip(feat_cols_important, clf_important.feature_importances_),\n",
    "                               key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) test the accuracy of our limited-feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90378900445765231"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(y_depression_test, y_important_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #4: Train a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) do some quick cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all variables (X's and Y's) into one dataframe\n",
    "all_variables_reg = pd.concat([X, Y_flourish, Y_depression, Y_anxiety], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape before removing NaNs:', (45756, 103))\n",
      "('shape after removing NaNs:', (8972, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with any NaN\n",
    "print('shape before removing NaNs:', all_variables_reg.shape)\n",
    "all_variables_reg = all_variables_reg.dropna(axis=0, how='any')\n",
    "print('shape after removing NaNs:', all_variables_reg.shape) # NOTE: 25,000+ dropped rows were due to AAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split big dataframe back up\n",
    "X = all_variables.drop(labels=['flourish', 'deprawsc', 'anx_score'], axis=1)\n",
    "Y_flourish_reg = all_variables['flourish']\n",
    "Y_depression_reg = all_variables['deprawsc']\n",
    "Y_anxiety_reg = all_variables['anx_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train_reg, X_test_reg = train_test_split(X, test_size=0.3, random_state=0)\n",
    "y_flourish_train_reg, y_flourish_test_reg = train_test_split(Y_flourish_reg, test_size=0.3, random_state=0)\n",
    "y_depression_train_reg, y_depression_test_reg = train_test_split(Y_depression_reg, test_size=0.3, random_state=0)\n",
    "y_anxiety_train_reg, y_anxiety_test_reg = train_test_split(Y_anxiety_reg, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) create and train the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random forest regressors\n",
    "dep_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "anx_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "flo_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=100, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifiers on all three outcomes\n",
    "dep_clf_reg.fit(X_train_reg, y_depression_train_reg)\n",
    "anx_clf_reg.fit(X_train_reg, y_anxiety_train_reg)\n",
    "flo_clf_reg.fit(X_train_reg, y_flourish_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.844880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.146528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>educ_par2</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>educ_par1</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hours_work_paid</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  importance\n",
       "0              AAQ    0.844880\n",
       "1         aca_impa    0.146528\n",
       "2           fincur    0.005930\n",
       "3          finpast    0.000753\n",
       "4          persist    0.000668\n",
       "5        educ_par2    0.000232\n",
       "6        educ_par1    0.000217\n",
       "7  hours_work_paid    0.000195\n",
       "8           gpa_sr    0.000100\n",
       "9           sexual    0.000082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "for clf in [dep_clf_reg, anx_clf_reg, flo_clf_reg]:\n",
    "    features = pd.DataFrame(sorted(zip(feat_cols, clf.feature_importances_),\n",
    "                            key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "    #display(features.head(10))\n",
    "    if clf == dep_clf_reg:\n",
    "        display(features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) test the accuracy of our full-feature classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create RMSE function as absolute measure of fit\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression Model R-squared:', 0.72616560409576358)\n",
      "('Anxiety Model R-squared:', 0.70718533969240571)\n",
      "('Flourishing Model R-squared:', 0.49172514402456996)\n",
      "\n",
      "\n",
      "('Depression Model RMSE:', 4.1037553048221866)\n",
      "('Anxiety Model RMSE:', 3.769722650655833)\n",
      "('Flourishing Model RMSE:', 38.551297282903413)\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred_dep_reg = dep_clf_reg.predict(X_test_reg)\n",
    "y_pred_anx_reg = anx_clf_reg.predict(X_test_reg)\n",
    "y_pred_flo_reg = flo_clf_reg.predict(X_test_reg)\n",
    "\n",
    "# Measure Goodness-of-Fit\n",
    "print(\"Depression Model R-squared:\", dep_clf_reg.score(X_test_reg, y_depression_test_reg))\n",
    "print(\"Anxiety Model R-squared:\", anx_clf_reg.score(X_test_reg, y_anxiety_test_reg))\n",
    "print(\"Flourishing Model R-squared:\", flo_clf_reg.score(X_test_reg, y_flourish_test_reg))\n",
    "print('\\n')\n",
    "print(\"Depression Model RMSE:\", rmse(y_pred_dep_reg, y_depression_test_reg))\n",
    "print(\"Anxiety Model RMSE:\", rmse(y_pred_anx_reg, y_anxiety_test_reg))\n",
    "print(\"Flourishing Model RMSE:\", rmse(y_pred_flo_reg, y_anxiety_test_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">R-squared</span> measures the <span style=\"color:red\">proportion of variability</span> in Y explained by the regression model (a useful benchmark for comparing models)\n",
    "#### <span style=\"color:red\">RMSE</span> measures the <span style=\"color:red\">standard deviation of the residuals</span> (the spread of the points about the fitted regression line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) compare performance to baseline measure (dummyRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression BASELINE R-Squared', -0.32434011555204822)\n",
      "('Anxiety BASELINE R-Squared', -0.22440938066905858)\n",
      "('Flourishing BASELINE R-Squared', -0.18083339171710611)\n",
      "\n",
      "\n",
      "('Depression BASELINE RMSE:', 9.0247924986332961)\n",
      "('Anxiety BASELINE RMSE:', 7.7086142740927119)\n",
      "('Flourishing BASELINE RMSE:', 11.72321961568168)\n"
     ]
    }
   ],
   "source": [
    "# Question: \"what if we just guessed the *median value* everytime?\"\n",
    "y_median_pred_dep_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_depression_train_reg).predict(X_test_reg)\n",
    "y_median_pred_anx_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_anxiety_train_reg).predict(X_test_reg)\n",
    "y_median_pred_flo_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_flourish_train_reg).predict(X_test_reg)\n",
    "\n",
    "# use arrays of median values to make baseline predictions\n",
    "print('Depression BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_depression_train_reg).score(X_test_reg, y_depression_test_reg))\n",
    "print('Anxiety BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_anxiety_train_reg).score(X_test_reg, y_anxiety_test_reg))\n",
    "print('Flourishing BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_flourish_train_reg).score(X_test_reg, y_flourish_test_reg))\n",
    "print('\\n')\n",
    "print('Depression BASELINE RMSE:', rmse(y_median_pred_dep_reg, y_depression_test_reg))\n",
    "print('Anxiety BASELINE RMSE:', rmse(y_median_pred_anx_reg, y_anxiety_test_reg))\n",
    "print('Flourishing BASELINE RMSE:', rmse(y_median_pred_flo_reg, y_flourish_test_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> The predictive models created above are 95-105% better fits than their baseline measures: </span>\n",
    "- #### <span style=\"color:red\">Depression Regressor: R-Squared = 0.73 // RMSE = 4.10 </span> in predicting a student's depression level\n",
    "- #### <span style=\"color:red\">Anxiety Regressor: R-Squared = 0.71 // RMSE = 3.77 </span>in predicting a student's anxiety level\n",
    "- #### <span style=\"color:red\">Flourishing Regressor: R-Squared = 0.49 // RMSE = 38.5 </span>in predicting a student's psychological well-being level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #3: Optimize Regressor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) optimize hyperparameters using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-686-d3eb015cb675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mCV_rfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_depression_train_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 327\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AJGoldstein/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score = True) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\"criterion\" : ['mse', 'mae'],\n",
    "              \"n_estimators\" : [500, 1000],\n",
    "              \"max_depth\" : [3, 5, 10, 15],\n",
    "              \"max_features\" : [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\" : [10, 30, 50, 100]}\n",
    " \n",
    "CV_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=5)\n",
    "CV_rfr.fit(X_train_reg, y_depression_train_reg)\n",
    "print CV_rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0)\n",
    "y_flourish_train, y_flourish_test = train_test_split(Y_flourish_cats, test_size=0.3, random_state=0)\n",
    "y_depression_train, y_depression_test = train_test_split(Y_depression_cats, test_size=0.3, random_state=0)\n",
    "y_anxiety_train, y_anxiety_test = train_test_split(Y_anxiety_cats, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.292482\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 6280\n",
      "Model:                          Logit   Df Residuals:                     6278\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 08 Dec 2017   Pseudo R-squ.:                  0.5757\n",
      "Time:                        13:01:31   Log-Likelihood:                -1836.8\n",
      "converged:                       True   LL-Null:                       -4328.8\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.8628      0.139    -42.050      0.000      -6.136      -5.590\n",
      "x1             0.2659      0.006     42.038      0.000       0.254       0.278\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "logit_model = sm.Logit(y_depression_train.reshape(-1,1), sm.add_constant(X_train['AAQ'].reshape(-1,1)))\n",
    "results = logit_model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AAQ Odds Ratio (statsmodels):', 1.3046626538540764)\n"
     ]
    }
   ],
   "source": [
    "print('AAQ Odds Ratio (statsmodels):', np.exp(results.params)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Interpretation: For every 1 unit increase in a student's AAQ score, we expect their odds of being depressed to increase by 30%</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train.AAQ.reshape(-1,1), y_depression_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AAQ Odds Ratio (sklearn):', array([[ 1.29847186]]))\n"
     ]
    }
   ],
   "source": [
    "# check odds ratio\n",
    "print('AAQ Odds Ratio (sklearn):', np.exp(logreg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEOCAYAAACXX1DeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcaYiCxRGGOMicgShTHGmIj+HwKJCsHrXXrcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f689990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the predicted probabilities of depression across the spectrum of AAQ\n",
    "plt.scatter(X_train.AAQ.reshape(-1,1), y_depression_train.reshape(-1,1))\n",
    "plt.plot(X_train.AAQ.reshape(-1,1), logreg.predict_proba(X_train.AAQ.reshape(-1,1))[:, 1], color='red')\n",
    "plt.xlabel('AAQ score')\n",
    "plt.ylabel('probability of depression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression Model Accuracy:', 0.88707280832095092)\n"
     ]
    }
   ],
   "source": [
    "y_dep_preds = logreg.predict(X_test.AAQ.reshape(-1,1))\n",
    "\n",
    "print('Depression Model Accuracy:', accuracy_score(y_depression_test, y_dep_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.884\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "results = model_selection.cross_val_score(modelCV, X_train.AAQ.reshape(-1,1), y_depression_train.reshape(-1,1), cv=kfold, scoring='accuracy')\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Predicted: Depressed  Predicted: Not Depressed\n",
      "Actual: Depressed                      1349                       128\n",
      "Actual: Not Depressed                   176                      1039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_depression_test, y_dep_preds)\n",
    "confusion_df = pd.DataFrame(confusion_matrix, index = ['Actual: Depressed', 'Actual: Not Depressed'], columns = ['Predicted: Depressed', 'Predicted: Not Depressed'])\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90      1477\n",
      "          1       0.89      0.86      0.87      1215\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_depression_test, y_dep_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "- The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "- The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall.\n",
    "- The support is the number of occurrences of each class in y_test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
