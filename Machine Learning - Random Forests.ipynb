{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMS Capstone - Machine Learning - Random Forests\n",
    "## By: AJ Goldstein (https://github.com/ajva1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Modeling Task: </span>\n",
    "### Understand the relationship between psychological inflexibility (i.e. AAQ) and mental health outcomes (i.e. depression, anxiety, well-being) while controlling for key demographic info (i.e. race, gender, field of study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Why Random Forests?</span>\n",
    "- WHY 1: <b>high interpretability & stable feature importances</b>\n",
    "- WHY 2: <b>reduces variance & prevents overfitting</b>\n",
    "- WHY 3: <b>inherently models feature interactions</b>\n",
    "\n",
    "### <span style=\"color:red\">Analysis Steps:</span>\n",
    "- 1) Prepare data for classification\n",
    "- 2) Train a Random Forest Classifier\n",
    "- 3) Optimize Classifier Models\n",
    "- 4) Train a Random Forest Regressor\n",
    "- 5) Optimize Regressor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #0: Carry forward data from previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleaned dataset\n",
    "%store -r HMS\n",
    "\n",
    "# separated modules\n",
    "%store -r HMS_ids\n",
    "%store -r HMS_demo\n",
    "%store -r HMS_mhstatus\n",
    "%store -r HMS_mhhelp\n",
    "%store -r HMS_aaq\n",
    "\n",
    "# tidy variable groups\n",
    "%store -r tidy_race\n",
    "%store -r tidy_religion\n",
    "%store -r tidy_degreeType\n",
    "%store -r tidy_fieldOfStudy\n",
    "%store -r tidy_activity\n",
    "%store -r tidy_age\n",
    "%store -r tidy_gender\n",
    "%store -r tidy_relig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #1: Prepare data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) convert survey demographics & AAQ into features matrix (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns without text \n",
    "cols = [col for col in HMS_demo.columns if ('text' not in col)]\n",
    "X = HMS_demo[cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert them to categorical variables\n",
    "for col in cols:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAQ</th>\n",
       "      <th>age</th>\n",
       "      <th>sex_birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>sexual</th>\n",
       "      <th>relship</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_ainaan</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_his_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>disab_1_1</th>\n",
       "      <th>disab_1_2</th>\n",
       "      <th>disab_1_3</th>\n",
       "      <th>disab_1_4</th>\n",
       "      <th>disab_1_5</th>\n",
       "      <th>disab_1_6</th>\n",
       "      <th>disab_1_7</th>\n",
       "      <th>disab_1_8</th>\n",
       "      <th>disab_1_9</th>\n",
       "      <th>disab_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAQ   age sex_birth gender sexual relship race_black race_ainaan  \\\n",
       "0  NaN  20.0       1.0    2.0    1.0     1.0        0.0         0.0   \n",
       "1  NaN  21.0       1.0    2.0    1.0     1.0        0.0         0.0   \n",
       "3  NaN  22.0       2.0    1.0    1.0     1.0        0.0         0.0   \n",
       "4  NaN  19.0       2.0    1.0    1.0     6.0        0.0         0.0   \n",
       "5  NaN  21.0       2.0    1.0    1.0     1.0        0.0         0.0   \n",
       "\n",
       "  race_asian race_his_temp   ...   disab_1_1 disab_1_2 disab_1_3 disab_1_4  \\\n",
       "0        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "1        0.0           0.0   ...         0.0       0.0       1.0       0.0   \n",
       "3        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "4        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "5        0.0           0.0   ...         0.0       0.0       0.0       0.0   \n",
       "\n",
       "  disab_1_5 disab_1_6 disab_1_7 disab_1_8 disab_1_9 disab_3  \n",
       "0       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "1       0.0       0.0       0.0       0.0       0.0     3.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "4       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "5       0.0       0.0       0.0       0.0       0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add in AAQ_total score\n",
    "X.insert(loc=0, column = 'AAQ', value = HMS_aaq['AAQ_total'])\n",
    "feat_cols = X.columns\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) remove unapplicable and missing values (NaN's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select three main outcomes\n",
    "Y_flourish = HMS_mhstatus['flourish']\n",
    "Y_depression = HMS_mhstatus['deprawsc']\n",
    "Y_anxiety = HMS_mhstatus['anx_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all variables (X's and Y's) into one dataframe\n",
    "all_variables = pd.concat([X, Y_flourish, Y_depression, Y_anxiety], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape before removing NaNs:', (45756, 103))\n",
      "('shape after removing NaNs:', (22781, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with any NaN\n",
    "print('shape before removing NaNs:', all_variables.shape)\n",
    "all_variables = all_variables.dropna(axis=0, how='any')\n",
    "print('shape after removing NaNs:', all_variables.shape) # NOTE: 25,000+ dropped rows were due to AAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> IMPORTANT NOTE: 25,000+ dropped rows were due to AAQ (half of respondents did not have a score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape BEFORE removing middle 1/3 of scores:', (22781, 103))\n",
      "('shape AFTER removing middle 1/3 of scores:', (8972, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove middle 1/3 of scores in the \"mild\" range\n",
    "print('shape BEFORE removing middle 1/3 of scores:', all_variables.shape)\n",
    "all_variables = all_variables.loc[~all_variables['flourish'].between(42, 47, inclusive=True)]\n",
    "all_variables = all_variables.loc[~all_variables['deprawsc'].between(5, 9, inclusive=True)]\n",
    "all_variables = all_variables.loc[~all_variables['anx_score'].between(5, 9, inclusive=True)]\n",
    "print('shape AFTER removing middle 1/3 of scores:', all_variables.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> IMPORTANT NOTE: 13,000 rows were dropped from the \"mild\" range of these scores</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big dataframe back up\n",
    "X = all_variables.drop(labels=['flourish', 'deprawsc', 'anx_score'], axis=1)\n",
    "Y_flourish_cleaned = all_variables['flourish']\n",
    "Y_depression_cleaned = all_variables['deprawsc']\n",
    "Y_anxiety_cleaned = all_variables['anx_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) categorize mental health outcomes into classified labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_outcome(value, outcome):\n",
    "    \n",
    "    # flourishing scale\n",
    "    if outcome == 'flourish':\n",
    "        if pd.isnull(value):\n",
    "            return value\n",
    "        elif value < 48:\n",
    "            return 0\n",
    "        elif value >= 48:\n",
    "            return 1\n",
    "        \n",
    "    # depression or anxiety\n",
    "    else:\n",
    "        if pd.isnull(value):\n",
    "            return value\n",
    "        elif value < 10:\n",
    "            return 0\n",
    "        elif value >= 10:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical labels\n",
    "Y_flourish_cats = pd.Series([categorize_outcome(score, 'flourish') for score in Y_flourish_cleaned], name='flourish')\n",
    "Y_depression_cats = pd.Series([categorize_outcome(score, 'depression') for score in Y_depression_cleaned], name = 'depression')\n",
    "Y_anxiety_cats = pd.Series([categorize_outcome(score, 'anxiety') for score in Y_anxiety_cleaned], name = 'anxiety')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">NOTE: using \"moderate\" score of 10 as cutoff for depression/anxiety... 48 as the threshold for positive mental health</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #2: Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0)\n",
    "y_flourish_train, y_flourish_test = train_test_split(Y_flourish_cats, test_size=0.3, random_state=0)\n",
    "y_depression_train, y_depression_test = train_test_split(Y_depression_cats, test_size=0.3, random_state=0)\n",
    "y_anxiety_train, y_anxiety_test = train_test_split(Y_anxiety_cats, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) create and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random forest classifiers\n",
    "dep_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "anx_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "flo_clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on all three outcomes\n",
    "dep_clf.fit(X_train, y_depression_train)\n",
    "anx_clf.fit(X_train, y_anxiety_train)\n",
    "flo_clf.fit(X_train, y_flourish_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.366570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.269347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.106480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.093753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.044024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.031884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.017441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>religios</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relig_aff_ch</td>\n",
       "      <td>0.006497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  importance\n",
       "0           AAQ    0.366570\n",
       "1      aca_impa    0.269347\n",
       "2       persist    0.106480\n",
       "3        fincur    0.093753\n",
       "4        sexual    0.044024\n",
       "5       finpast    0.031884\n",
       "6        gpa_sr    0.017441\n",
       "7      religios    0.010687\n",
       "8        gender    0.009129\n",
       "9  relig_aff_ch    0.006497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "for clf in [dep_clf, anx_clf, flo_clf]:\n",
    "    features = pd.DataFrame(sorted(zip(feat_cols, clf.feature_importances_),\n",
    "                            key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "    #display(features.head(10))\n",
    "    if clf == dep_clf:\n",
    "        display(features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">AAQ consistently comes out on top as by far the most important feature</span>\n",
    "- #### <span style=\"color:red\">(10x more important than any variable outside the top 5 in predicting mental health outcomes)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) test the accuracy of our full-feature classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression Model Accuracy:', 0.90973254086181277)\n",
      "('Anxiety Model Accuracy:', 0.89635958395245174)\n",
      "('Flourishing Model Accuracy:', 0.84658246656760772)\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred_dep = dep_clf.predict(X_test)\n",
    "y_pred_anx = anx_clf.predict(X_test)\n",
    "y_pred_flo = flo_clf.predict(X_test)\n",
    "\n",
    "# Print the Accuracy Of Our Full Feature Model\n",
    "print('Depression Model Accuracy:', accuracy_score(y_depression_test, y_pred_dep))\n",
    "print('Anxiety Model Accuracy:', accuracy_score(y_anxiety_test, y_pred_anx))\n",
    "print('Flourishing Model Accuracy:', accuracy_score(y_flourish_test, y_pred_flo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) compare performance to baseline measure (dummyClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression BASELINE Accuracy:', 0.54866270430906394)\n",
      "('Anxiety BASELINE Accuracy:', 0.57206537890044573)\n",
      "('Flourishing BASELINE Accuracy:', 0.56723625557206536)\n"
     ]
    }
   ],
   "source": [
    "# Question: \"what if we just guessed the *most common class* everytime?\"\n",
    "y_mode_pred_dep = DummyClassifier(strategy='most_frequent').fit(X_train, y_depression_train).predict(X_test)\n",
    "y_mode_pred_anx = DummyClassifier(strategy='most_frequent').fit(X_train, y_anxiety_train).predict(X_test)\n",
    "y_mode_pred_flo = DummyClassifier(strategy='most_frequent').fit(X_train, y_flourish_train).predict(X_test)\n",
    "\n",
    "# use arrays of mode values to make baseline predictions\n",
    "print('Depression BASELINE Accuracy:', accuracy_score(y_depression_test, y_mode_pred_dep))\n",
    "print('Anxiety BASELINE Accuracy:', accuracy_score(y_anxiety_test, y_mode_pred_anx))\n",
    "print('Flourishing BASELINE Accuracy:', accuracy_score(y_flourish_test, y_mode_pred_flo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> The predictive models created above are 35-40% more accurate than their baseline measures: </span>\n",
    "- #### <span style=\"color:red\">Depression Classifer: ~92% accuracy</span> in predicting whether or not a student is clinically depressed\n",
    "- #### <span style=\"color:red\">Anxiety Classifer: ~90% accuracy </span>in predicting whether or not a student has general anxiety disorder\n",
    "- #### <span style=\"color:red\">Flourishing Classifer: ~85% accuracy </span>in predicting whether or not someone has positive mental health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #3: Optimize Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) optimize hyperparameters using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "rfc = RandomForestClassifier(n_estimators = 1000, n_jobs=-1, oob_score = True) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\"criterion\" : ['gini', 'entropy'],\n",
    "              \"max_depth\" : [3, 4, 5, 6],\n",
    "              \"max_features\" : [4, 6, 8, 10],\n",
    "              \"min_samples_leaf\" : [10, 20, 30, 50]}\n",
    " \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_train, y_depression_train)\n",
    "print CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"n_estimators\" : [10, 100, 500, 1000, 10000, 100000],\n",
    "           \"max_features\" : [1, 2, 4, 8, 16, 32],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "            \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) identify and select the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAQ\n",
      "sexual\n",
      "fincur\n",
      "finpast\n",
      "aca_impa\n",
      "persist\n"
     ]
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0\n",
    "sfm = SelectFromModel(clf, threshold=0.03)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_depression_train)\n",
    "\n",
    "# Print the names of the most important features\n",
    "feat_cols_important = []\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    feat_cols_important.append(feat_cols[feature_list_index])\n",
    "    print(feat_cols[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) create a dataset with only the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) train new classifiers using only the most important features ( + optimal hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 10, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_depression_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.505255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.265576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.077233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.072019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.046874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.033042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  importance\n",
       "0       AAQ    0.505255\n",
       "1  aca_impa    0.265576\n",
       "2    fincur    0.077233\n",
       "3   persist    0.072019\n",
       "4   finpast    0.046874\n",
       "5    sexual    0.033042"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "features = pd.DataFrame(sorted(zip(feat_cols_important, clf_important.feature_importances_),\n",
    "                               key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) test the accuracy of our limited-feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90378900445765231"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(y_depression_test, y_important_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #4: Train a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) do some quick cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all variables (X's and Y's) into one dataframe\n",
    "all_variables_reg = pd.concat([X, Y_flourish, Y_depression, Y_anxiety], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shape before removing NaNs:', (45756, 103))\n",
      "('shape after removing NaNs:', (8972, 103))\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with any NaN\n",
    "print('shape before removing NaNs:', all_variables_reg.shape)\n",
    "all_variables_reg = all_variables_reg.dropna(axis=0, how='any')\n",
    "print('shape after removing NaNs:', all_variables_reg.shape) # NOTE: 25,000+ dropped rows were due to AAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split big dataframe back up\n",
    "X = all_variables.drop(labels=['flourish', 'deprawsc', 'anx_score'], axis=1)\n",
    "Y_flourish_reg = all_variables['flourish']\n",
    "Y_depression_reg = all_variables['deprawsc']\n",
    "Y_anxiety_reg = all_variables['anx_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "X_train_reg, X_test_reg = train_test_split(X, test_size=0.3, random_state=0)\n",
    "y_flourish_train_reg, y_flourish_test_reg = train_test_split(Y_flourish_reg, test_size=0.3, random_state=0)\n",
    "y_depression_train_reg, y_depression_test_reg = train_test_split(Y_depression_reg, test_size=0.3, random_state=0)\n",
    "y_anxiety_train_reg, y_anxiety_test_reg = train_test_split(Y_anxiety_reg, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) create and train the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random forest regressors\n",
    "dep_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "anx_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)\n",
    "\n",
    "flo_clf_reg = RandomForestRegressor(n_estimators=1000, max_features = \"auto\", max_depth = 5,\n",
    "                             min_samples_leaf = 100, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=100, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifiers on all three outcomes\n",
    "dep_clf_reg.fit(X_train_reg, y_depression_train_reg)\n",
    "anx_clf_reg.fit(X_train_reg, y_anxiety_train_reg)\n",
    "flo_clf_reg.fit(X_train_reg, y_flourish_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQ</td>\n",
       "      <td>0.844880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca_impa</td>\n",
       "      <td>0.146528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fincur</td>\n",
       "      <td>0.005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finpast</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>persist</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>educ_par2</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>educ_par1</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hours_work_paid</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpa_sr</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sexual</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  importance\n",
       "0              AAQ    0.844880\n",
       "1         aca_impa    0.146528\n",
       "2           fincur    0.005930\n",
       "3          finpast    0.000753\n",
       "4          persist    0.000668\n",
       "5        educ_par2    0.000232\n",
       "6        educ_par1    0.000217\n",
       "7  hours_work_paid    0.000195\n",
       "8           gpa_sr    0.000100\n",
       "9           sexual    0.000082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "for clf in [dep_clf_reg, anx_clf_reg, flo_clf_reg]:\n",
    "    features = pd.DataFrame(sorted(zip(feat_cols, clf.feature_importances_),\n",
    "                            key=lambda x: x[1], reverse=True), columns = ['name', 'importance'])\n",
    "    #display(features.head(10))\n",
    "    if clf == dep_clf_reg:\n",
    "        display(features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) test the accuracy of our full-feature classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create RMSE function as absolute measure of fit\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression Model R-squared:', 0.72616560409576358)\n",
      "('Anxiety Model R-squared:', 0.70718533969240571)\n",
      "('Flourishing Model R-squared:', 0.49172514402456996)\n",
      "\n",
      "\n",
      "('Depression Model RMSE:', 4.1037553048221866)\n",
      "('Anxiety Model RMSE:', 3.769722650655833)\n",
      "('Flourishing Model RMSE:', 38.551297282903413)\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred_dep_reg = dep_clf_reg.predict(X_test_reg)\n",
    "y_pred_anx_reg = anx_clf_reg.predict(X_test_reg)\n",
    "y_pred_flo_reg = flo_clf_reg.predict(X_test_reg)\n",
    "\n",
    "# Measure Goodness-of-Fit\n",
    "print(\"Depression Model R-squared:\", dep_clf_reg.score(X_test_reg, y_depression_test_reg))\n",
    "print(\"Anxiety Model R-squared:\", anx_clf_reg.score(X_test_reg, y_anxiety_test_reg))\n",
    "print(\"Flourishing Model R-squared:\", flo_clf_reg.score(X_test_reg, y_flourish_test_reg))\n",
    "print('\\n')\n",
    "print(\"Depression Model RMSE:\", rmse(y_pred_dep_reg, y_depression_test_reg))\n",
    "print(\"Anxiety Model RMSE:\", rmse(y_pred_anx_reg, y_anxiety_test_reg))\n",
    "print(\"Flourishing Model RMSE:\", rmse(y_pred_flo_reg, y_anxiety_test_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">R-squared</span> measures the <span style=\"color:red\">proportion of variability</span> in Y explained by the regression model (a useful benchmark for comparing models)\n",
    "#### <span style=\"color:red\">RMSE</span> measures the <span style=\"color:red\">standard deviation of the residuals</span> (the spread of the points about the fitted regression line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) compare performance to baseline measure (dummyRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Depression BASELINE R-Squared', -0.32434011555204822)\n",
      "('Anxiety BASELINE R-Squared', -0.22440938066905858)\n",
      "('Flourishing BASELINE R-Squared', -0.18083339171710611)\n",
      "\n",
      "\n",
      "('Depression BASELINE RMSE:', 9.0247924986332961)\n",
      "('Anxiety BASELINE RMSE:', 7.7086142740927119)\n",
      "('Flourishing BASELINE RMSE:', 11.72321961568168)\n"
     ]
    }
   ],
   "source": [
    "# Question: \"what if we just guessed the *median value* everytime?\"\n",
    "y_median_pred_dep_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_depression_train_reg).predict(X_test_reg)\n",
    "y_median_pred_anx_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_anxiety_train_reg).predict(X_test_reg)\n",
    "y_median_pred_flo_reg = DummyRegressor(strategy='median').fit(X_train_reg, y_flourish_train_reg).predict(X_test_reg)\n",
    "\n",
    "# use arrays of median values to make baseline predictions\n",
    "print('Depression BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_depression_train_reg).score(X_test_reg, y_depression_test_reg))\n",
    "print('Anxiety BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_anxiety_train_reg).score(X_test_reg, y_anxiety_test_reg))\n",
    "print('Flourishing BASELINE R-Squared', DummyRegressor(strategy='median').fit(X_train_reg, y_flourish_train_reg).score(X_test_reg, y_flourish_test_reg))\n",
    "print('\\n')\n",
    "print('Depression BASELINE RMSE:', rmse(y_median_pred_dep_reg, y_depression_test_reg))\n",
    "print('Anxiety BASELINE RMSE:', rmse(y_median_pred_anx_reg, y_anxiety_test_reg))\n",
    "print('Flourishing BASELINE RMSE:', rmse(y_median_pred_flo_reg, y_flourish_test_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> The predictive models created above are 95-105% better fits than their baseline measures: </span>\n",
    "- #### <span style=\"color:red\">Depression Regressor: R-Squared = 0.73 // RMSE = 4.10 </span> in predicting a student's depression level\n",
    "- #### <span style=\"color:red\">Anxiety Regressor: R-Squared = 0.71 // RMSE = 3.77 </span>in predicting a student's anxiety level\n",
    "- #### <span style=\"color:red\">Flourishing Regressor: R-Squared = 0.49 // RMSE = 38.5 </span>in predicting a student's psychological well-being level "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
